# @package _global_
system:
  system_name: ${env.env_name}/${env.scenario.task_name}/ff_mz/ # Name of the system.
  epochs: 128 # Number of epochs per training data batch.
  total_buffer_size: 8192 # Total effective size of the replay buffer across all devices and vectorised update steps. This means each device has a buffer of size buffer_size//num_devices which is further divided by the update_batch_size. This value must be divisible by num_devices*update_batch_size.
  total_batch_size: 512 # Total effective number of samples to train on. This means each device has a batch size of batch_size/num_devices which is further divided by the update_batch_size. This value must be divisible by num_devices*update_batch_size.
  gamma: 0.997 # Discounting factor.
  critic_vmin: -20.0 # Minimum value for the critic.
  critic_vmax: 20.0 # Maximum value for the critic.
  critic_num_atoms: 41 # Number of atoms for the categorical critic head.
  reward_vmin: -20.0 # Minimum value for the reward.
  reward_vmax: 20.0 # Maximum value for the reward.
  reward_num_atoms: 41 # Number of atoms for the categorical reward head.
